{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "-Try operations for a single year's data first (all preprocessing steps)\n",
    "\n",
    "Preprocessing notes (single year, multi years, etc)\n",
    "\n",
    "Filtration based on shootings procedure:\n",
    "\n",
    "(1*) Retain any municipality where a shooting occurred ever (when working with a single year, it doesn't really matter, just filter based on shooting)\n",
    "\n",
    "Over many years, this may include places with changed crime profiles, which is bad\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2*) Retain all data for a year in a municipality when there was a shooting that year (same as option 1* for a single year's data)\n",
    "\n",
    "Over many years, this means retaining all samples from the year where the shooting ocurred for that municipality; this has the benefit of interpretability: every sample is just a troubled year municipality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post column creation:\n",
    "\n",
    "Need to make post-1, post-2, ... , post-6 month indicator columns (initialize to 0)\n",
    "\n",
    "Figure out how to do this efficiently LOL\n",
    "\n",
    "Pre column creation:\n",
    "\n",
    "Need to make a pre (treatment) column (post = -1 in estimating equation) (use shift=-1, think about whether min/max needs to be changed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column transformations\n",
    "\n",
    "Total assaults, total killings\n",
    "    \n",
    "z-scored force sizes, force size as a percentage of population column (check if it exists first)\n",
    "\n",
    "Join arrests, calculate total arrests, take log of arrests as new response variable\n",
    "\n",
    "Relevant summary statistics/notes to add in the introduction?\n",
    "\n",
    "Number of municipalities, number of municipalities preserved per year (on average) after filtration, number of officers shot and killed (on average) per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "leoka_17_monthly = pd.read_stata('ucr_leoka_monthly_1960_2020_dta/leoka_monthly_2017.dta')\n",
    "leoka_17_monthly.shape\n",
    "leoka_17_monthly = leoka_17_monthly.iloc[:,:-198] #drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "leoka_17_monthly['total_assaults'] = leoka_17_monthly['assaults_no_injury_total'] + leoka_17_monthly['assaults_with_injury_total']\n",
    "\n",
    "#filter into only the municipalities where there was at least one assault that year\n",
    "officer_assaulted = (leoka_17_monthly['total_assaults'] > 0)\n",
    "ori_to_keep = leoka_17_monthly.loc[officer_assaulted, 'ori'].unique()\n",
    "leoka_17_monthly = leoka_17_monthly[leoka_17_monthly['ori'].isin(ori_to_keep)]\n",
    "\n",
    "#leoka_17_monthly.shape --> 66372 x 59, means 5531 municipalities were kept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    leoka_17_monthly[f'PreviousTreatment_{i}'] = leoka_17_monthly.groupby('ori')['officers_killed_total'].shift(i)\n",
    "    leoka_17_monthly[f'post_{i}'] = leoka_17_monthly[f'PreviousTreatment_{i}'] > 0\n",
    "\n",
    "    #don't do the idxmin thing, shouldn't matter since things are NaN where edge case shifts; drop the NaNs by removing the PreviousTreament_i columns\n",
    "\n",
    "    leoka_17_monthly[f'post_{i}'] = leoka_17_monthly[f'post_{i}'].astype(int)\n",
    "    leoka_17_monthly = leoka_17_monthly.drop(columns=[f'PreviousTreatment_{i}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column transformations\n",
    "\n",
    "#force size mechanism construction\n",
    "min_size, max_size = leoka_17_monthly['total_employees_officers'].min(), leoka_17_monthly['total_employees_officers'].max()\n",
    "leoka_17_monthly['employment_norm'] = (leoka_17_monthly['total_employees_officers'] - min_size)/(max_size - min_size) #defaults to 0-1 range\n",
    "\n",
    "median_condition = leoka_17_monthly['total_employees_officers'] > leoka_17_monthly['total_employees_officers'].median()\n",
    "trueval, falseval = 1, 0\n",
    "leoka_17_monthly['employment_median_indicator'] = np.where(median_condition, trueval, falseval)\n",
    "\n",
    "\n",
    "#drop rows where population is 0\n",
    "leoka_17_monthly = leoka_17_monthly.loc[leoka_17_monthly['population'] > 0]\n",
    "\n",
    "#proportion mechanism\n",
    "leoka_17_monthly['employment_pop_proportion'] = leoka_17_monthly['total_employees_officers']/leoka_17_monthly['population']\n",
    "prop_median_condition = leoka_17_monthly['employment_pop_proportion'] > leoka_17_monthly['employment_pop_proportion'].median()\n",
    "leoka_17_monthly['employment_pop_prop_indicator'] = np.where(prop_median_condition, trueval, falseval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assault indicator (shoot_it) creation\n",
    "leoka_17_monthly['assault_indicator'] = (leoka_17_monthly['total_assaults'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add in arrest data\n",
    "arrests_17_monthly = pd.read_stata('ucr_arrests_monthly_index_1974_2018_dta/ucr_arrests_monthly_index_crimes_age_2017.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/mg9jv4jj4_zc1dsmj4zsf1vm0000gn/T/ipykernel_34443/1290676512.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  arrests_17_monthly['total_arrests'] = arrests_17_monthly['theft_tot_arrests'] + arrests_17_monthly['robbery_tot_arrests'] + arrests_17_monthly['rape_tot_arrests'] + arrests_17_monthly['murder_tot_arrests'] + arrests_17_monthly['mtr_veh_theft_tot_arrests'] + arrests_17_monthly['burglary_tot_arrests'] + arrests_17_monthly['arson_tot_arrests'] + arrests_17_monthly['agg_assault_tot_arrests']\n",
      "/var/folders/5h/mg9jv4jj4_zc1dsmj4zsf1vm0000gn/T/ipykernel_34443/1290676512.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  arrests_17_monthly['log_total_arrests'] = np.log(arrests_17_monthly['total_arrests'] + 1)\n"
     ]
    }
   ],
   "source": [
    "arrests_17_monthly['total_arrests'] = arrests_17_monthly['theft_tot_arrests'] + arrests_17_monthly['robbery_tot_arrests'] + arrests_17_monthly['rape_tot_arrests'] + arrests_17_monthly['murder_tot_arrests'] + arrests_17_monthly['mtr_veh_theft_tot_arrests'] + arrests_17_monthly['burglary_tot_arrests'] + arrests_17_monthly['arson_tot_arrests'] + arrests_17_monthly['agg_assault_tot_arrests']\n",
    "arrests_17_monthly['log_total_arrests'] = np.log(arrests_17_monthly['total_arrests'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "leoka_17_monthly = leoka_17_monthly.drop_duplicates(subset=['ori', 'month'])\n",
    "arrests_17_monthly = arrests_17_monthly.drop_duplicates(subset=['ori', 'month'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59328, 71), (154071, 631), (59328, 699))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrests_17_monthly.shape\n",
    "agg_data_2017 = pd.merge(leoka_17_monthly, arrests_17_monthly, on=['ori', 'month', 'year'], how='left')\n",
    "leoka_17_monthly.shape, arrests_17_monthly.shape, agg_data_2017.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data_2017.to_stata('year_17_1.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
